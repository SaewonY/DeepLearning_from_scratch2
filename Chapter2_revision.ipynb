{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 본질적인 문제는 컴퓨터가 우리 말을 이해하게 만드는 것이다.\n",
    "\n",
    "+ 이번 장에서는 고전적인 기법 (딥러닝 이전)에 대해서 알아보고자 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 자연어처리란?\n",
    "+ 우리가 평소에 쓰는 말을 자연어 natural language라고 한다. 따라서 자연어처리란 우리가 쓰는 말을 컴퓨터로 하여금 이해하게끔 만드는 기술 분야이다.\n",
    "\n",
    "+ 자연어는 살아 있는 언어이며 그 안에는 '부드러움'이 있다. 그렇기에 딱딱한 컴퓨터에서 자연어를 이해시키는 것은 평범한 방법으로는 도달 불가능하다.\n",
    "\n",
    "+ 현재 검색엔진이나 기계 번역과 같이 자연어처리 기술이 활용되고 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 단어의 의미\n",
    "단어의 의미를 이해하는데는 크게 3가지 방법이 있다.\n",
    "+ 시소러스를 활용 \n",
    "+ 통계 기반 기법 \n",
    "+ 추론 기반 기법 (word2vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 시소러스"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 단어의 의미를 나타내는 방법으로 가장 먼저 사람이 직접 단어의 의미를 정의하는 방식을 생각할 수 있다.\n",
    "\n",
    "+ 시소러스란 유의어 사전을 뜻한다. 동의어나 뜻이 비슷한 단어 (유의어)가 한 그룹으로 분류되어 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WordNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 자연어처리에서 각장 유명한 시소러스.\n",
    "\n",
    "+ 이를 활용해서 '단어 네트워크'를 얻을 수 있다. (현재는 안쓴다)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 시소러스의 문제점"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 시대 변화에 대응하기 어렵다. 신조어가 나오면 그때그때 추가할 것인가?\n",
    "\n",
    "+ 사람 쓰는 비용 문제. 예를 들어 영어 단어는 1000만 개가 넘는다. 이를 모두 사람이 정리하기엔 비용이 너무 크다.\n",
    "\n",
    "+ 단어의 미묘한 차이를 표현할 수 없다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 통계 기반 기법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파이썬으로 말뭉치 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'You say goodbye and I say hello.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'you say goodbye and i say hello  .'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = text.lower()\n",
    "text = text.replace('.', ' .')\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['you', 'say', 'goodbye', 'and', 'i', 'say', 'hello', '', '.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = text.split(' ')\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 딕셔너리 활용해서 id와 단어를 짝지어준다\n",
    "word_to_id = {}\n",
    "id_to_word = {}\n",
    "\n",
    "for word in words:\n",
    "    if word not in word_to_id:\n",
    "        new_id = len(word_to_id)\n",
    "        word_to_id[word] = new_id\n",
    "        id_to_word[new_id] = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '', 7: '.'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'you': 0, 'say': 1, 'goodbye': 2, 'and': 3, 'i': 4, 'hello': 5, '': 6, '.': 7}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'say'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 이처럼 id나 단어를 기반으로 검색 가능\n",
    "id_to_word[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_id['hello']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 1, 5, 6, 7])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "corpus = [word_to_id[w] for w in words]\n",
    "corpus = np.array(corpus)\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = text.replace('.', ' .')\n",
    "    words = text.split(' ')\n",
    "    \n",
    "    word_to_id = {}\n",
    "    id_to_word = {}\n",
    "\n",
    "    for word in words:\n",
    "        if word not in word_to_id:\n",
    "            new_id = len(word_to_id)\n",
    "            word_to_id[word] = new_id\n",
    "            id_to_word[new_id] = word\n",
    "            \n",
    "    corpus = [word_to_id[w] for w in words]\n",
    "    \n",
    "    return corpus, word_to_id, id_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 함수 활용하여 말뭉치 전처리\n",
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 단어의 분산 표현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 색을 'RGB' 채널로 표현하듯 단어도 벡터로 표현할 수 있다.\n",
    "+ 이를 자연어처리 분야에서는 'distributional representation'이라고 표현한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 분포 가설"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ '단어의 의미는 주변 단어에 의해 형성된다' = 분포 가설 (distributional hypothesis)\n",
    "+ 단어 자체에는 의미가 없고 맥락 (context)가 의미를 형성한다는 것.\n",
    "+ window size = 맥락의 크기. 윈도우 사이즈가 1이면 좌우 한 단어씩만 본다는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 동시발생 행렬 (co-occurence matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 주변 단어를 본다 => 주변 단어를 센다\n",
    "+ 이를 집계한 것이 동시발생 행렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 1, 5, 6]\n"
     ]
    }
   ],
   "source": [
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}\n"
     ]
    }
   ],
   "source": [
    "print(id_to_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'you'의 맥락으로써 동시에 발생하는 단어의 빈도를 나타내보면 다음과 같다.\n",
    "+ you 0 / say 1 / goodbye 0 / and 0 / i 0 / hello 0 / . 0\n",
    "+ 리를 벡터로 표현하면 [0, 1, 0, 0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "계속해서 모든 단어에 대해서 정리를 한다음 합쳐보면 다음과 같은 행렬을 얻을 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = np.array([\n",
    "    [0, 1, 0, 0, 0, 0, 0],\n",
    "    [1, 0, 1, 0, 1, 1, 0],\n",
    "    [0, 1, 0, 1, 0, 0, 0],\n",
    "    [0, 0, 1, 0, 1, 0, 0],\n",
    "    [0, 1, 0, 1, 0, 0, 0],\n",
    "    [0, 1, 0, 0, 0, 0, 1],\n",
    "    [0, 0, 0, 0, 0, 1, 0]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# ID가 0인 단어의 벡터 표현\n",
    "print(C[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#이와 같이 create_co_matrix라는 함수를 통해 동시발생 행렬을 만들어 낼 수 있다.\n",
    "\n",
    "def create_co_matrix(corpus, vocab_size, window_size=1):\n",
    "    corpus_size = len(corpus)\n",
    "    co_matrix = np.zeros((vocab_size, vocab_size), dtype=np.int32)\n",
    "    \n",
    "    for idx, word_id in enumerate(corpus):\n",
    "        for i in range(1, window_size + 1):\n",
    "            left_idx = idx - i\n",
    "            right_idx = idx + 1\n",
    "            \n",
    "            if left_idx >= 0:\n",
    "                left_word_id = corpus[left_idx]\n",
    "                co_matrix[word_id, left_word_id] += 1\n",
    "                \n",
    "            if right_idx < corpus_size:\n",
    "                right_word_id = corpus[right_idx]\n",
    "                co_matrix[word_id, right_word_id] += 1\n",
    "    return co_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 벡터 간 유사도"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 단어 벡터의 유사도를 나타낼 때는 cosine similarity를 사용한다.\n",
    "+ 분자에는 벡터의 내적, 분모에는 각 벡터의 norm이 들어간다.\n",
    "+ 직관적으로 풀어보면 '두 벡터가 가리키는 방향이 얼마나 비슷한가'이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_similarity(x, y):\n",
    "    nx = x / np.sqrt(np.sum(x**2))\n",
    "    ny = y / np.sqrt(np.sum(y**2))\n",
    "    return np.dot(nx, ny)\n",
    "# 이렇게하면 모든 원소가 0인 벡터가 들어올 경우 오류가 발생"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_similarity(x, y, eps=1e-8):\n",
    "    nx = x / np.sqrt(np.sum(x**2) + eps)\n",
    "    ny = y / np.sqrt(np.sum(y**2) + eps)\n",
    "    return np.dot(nx, ny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7071067758832467\n"
     ]
    }
   ],
   "source": [
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "vocab_size = len(word_to_id)\n",
    "C = create_co_matrix(corpus, vocab_size)\n",
    "\n",
    "c0 = C[word_to_id['you']]  # \"you\"의 단어 벡터\n",
    "c1 = C[word_to_id['i']]    # \"i\"의 단어 벡터\n",
    "print(cos_similarity(c0, c1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 유사 단어의 랭킹 표시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar(query, word_to_id, id_to_word, word_matrix, top=5):\n",
    "    \n",
    "    if query not in word_to_id:\n",
    "        print(\"%s(을)를 찾을 수 없습니다.\" % query)\n",
    "        \n",
    "    print('\\n[query] ' + query)\n",
    "    query_id = word_to_id[query]\n",
    "    query_vec = word_matrix[query_id]\n",
    "    \n",
    "    vocab_size = len(id_to_word)\n",
    "    similarity = np.zeros(vocab_size)\n",
    "    for i in range(vocab_size):\n",
    "        similarity[i] = cos_similarity(word_matrix[i], query_vec)\n",
    "        \n",
    "    count = 0\n",
    "    for i in (-1 * similarity).argsort():\n",
    "        if id_to_word[i] == query:\n",
    "            continue\n",
    "        print(\" %s %s\" % (id_to_word[i], similarity[i]))\n",
    "        \n",
    "        count += 1\n",
    "        if count >= top:\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[query] you\n",
      " goodbye 0.7071067758832467\n",
      " i 0.7071067758832467\n",
      " hello 0.7071067758832467\n",
      " say 0.0\n",
      " and 0.0\n"
     ]
    }
   ],
   "source": [
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "vocab_size = len(word_to_id)\n",
    "C = create_co_matrix(corpus, vocab_size)\n",
    "\n",
    "most_similar('you', word_to_id, id_to_word, C, top=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 통계 기반 기법 개선하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 상호정보량"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 단순하게 발생 빈도로만 mapping하면 별로 중요하지 않은 the와 같은 관사가 car와 같이 의미를 갖는 단어와 동일하게 들어간다.\n",
    "+ 이를 해결하기 위해 점별 상호정보량(PMI)를 사용한다.\n",
    "\n",
    "<br>\n",
    "\n",
    "+ PMI를 사용하면 \"car\"는 \"the\"보다 \"drive\"와 관련성이 강해진다.\n",
    "+ 동시발생 횟수가 0일 경우를 고려하여 양의 상호정보략(PPMI)를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ppmi(C, verbose=False, eps=1e-8):\n",
    "    M = np.zeros_like(C, dtype=np.float32)\n",
    "    N = np.sum(C)\n",
    "    S = np.sum(C, axis=0)\n",
    "    total = C.shape[0] * C.shape[1]\n",
    "    cnt = 0\n",
    "    \n",
    "    for i in range(C.shape[0]):\n",
    "        for j in range(C.shape[1]):\n",
    "            pmi = np.log2(C[i, j] * N / (S[j]*S[i]) + eps)\n",
    "            M[i, j] = max(0, pmi)\n",
    "            \n",
    "            if verbose:\n",
    "                cnt += 1\n",
    "                if cnt % (total//100) == 0:\n",
    "                    print('%.1f%% 완료' % (100*cnt/total))\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "동시발생 행렬\n",
      "[[0 1 0 0 0 0 0]\n",
      " [1 0 1 0 1 1 0]\n",
      " [0 1 0 1 0 0 0]\n",
      " [0 0 1 0 1 0 0]\n",
      " [0 1 0 1 0 0 0]\n",
      " [0 1 0 0 0 0 1]\n",
      " [0 0 0 0 0 1 0]]\n",
      "--------------------------------------------------\n",
      "PPMI\n",
      "[[0.    1.807 0.    0.    0.    0.    0.   ]\n",
      " [1.807 0.    0.807 0.    0.807 0.807 0.   ]\n",
      " [0.    0.807 0.    1.807 0.    0.    0.   ]\n",
      " [0.    0.    1.807 0.    1.807 0.    0.   ]\n",
      " [0.    0.807 0.    1.807 0.    0.    0.   ]\n",
      " [0.    0.807 0.    0.    0.    0.    2.807]\n",
      " [0.    0.    0.    0.    0.    2.807 0.   ]]\n"
     ]
    }
   ],
   "source": [
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "vocab_size = len(word_to_id)\n",
    "C = create_co_matrix(corpus, vocab_size)\n",
    "W = ppmi(C)\n",
    "\n",
    "np.set_printoptions(precision=3)  # 유효 자릿수를 세 자리로 표시\n",
    "print('동시발생 행렬')\n",
    "print(C)\n",
    "print('-'*50)\n",
    "print('PPMI')\n",
    "print(W)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 차원 감소"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 중요한 정보를 최대한 유지하면서 벡터의 차원을 줄일 수 있다.\n",
    "+ 차원을 감소시키는 방법은 여러가지이지만 여기서는 특잇값 분해 (singular value decomposition)을 활용한다.\n",
    "+ SVD는 임의의 행렬을 세 행렬의 곱으로 분해한다. => X = U * S * V.transpose\n",
    "+ U와 V는 직교행렬(orthogonal matrix)이고, 그 열 벡터는 직교한다. S는 대각행렬(대각성분 외에는 모두 0인 행렬)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "행렬 U에서 여분의 열벡터를 깎아내어 원래의 행렬을 근사할 수 있다! (자세한 그림은 책 참조)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVD에 의한 차원 감소"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "vocab_size = len(id_to_word)\n",
    "C = create_co_matrix(corpus, vocab_size, window_size=1)\n",
    "W = ppmi(C)\n",
    "\n",
    "# SVD\n",
    "U, S, V = np.linalg.svd(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(C[0]) # 동시발생 행렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.    1.807 0.    0.    0.    0.    0.   ]\n"
     ]
    }
   ],
   "source": [
    "print(W[0]) # PPMI 행렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.000e+00  3.409e-01 -1.205e-01 -3.886e-16 -1.110e-16 -9.323e-01\n",
      " -2.426e-17]\n"
     ]
    }
   ],
   "source": [
    "print(U[0]) # SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.    0.341]\n"
     ]
    }
   ],
   "source": [
    "# 여기서 이 밀집벡터의 차원을 감소시키려면 단순히 처음 두 원소를 꺼내면 된다.\n",
    "print(U[0, :2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for word, word_id in word_to_id.items():\n",
    "    plt.annotate(word, (U[word_id, 0], U[word_id, 1]))\n",
    "plt.scatter(U[:,0], U[:,1], alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PTB 데이터셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이제부터는 너무 작지도 너무 크지도 않은 적당한 크기의 말뭉치를 이용한다.\n",
    "# PTB 데이터셋은 주어진 기법의 품질 측정용으로 많이 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import ptb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ptb.train.txt ... \n",
      "Done\n",
      "말뭉치 크기: 929589\n",
      "corpus[:30]: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29]\n",
      "\n",
      "id_to_word[0]: aer\n",
      "id_to_word[1]: banknote\n",
      "id_to_word[2]: berlitz\n",
      "\n",
      "word_to_id['car']: 3856\n",
      "word_to_id['happy']: 4428\n",
      "word_to_id['lexus']: 7426\n"
     ]
    }
   ],
   "source": [
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "\n",
    "print('말뭉치 크기:', len(corpus))\n",
    "print('corpus[:30]:', corpus[:30])\n",
    "print()\n",
    "print('id_to_word[0]:', id_to_word[0])\n",
    "print('id_to_word[1]:', id_to_word[1])\n",
    "print('id_to_word[2]:', id_to_word[2])\n",
    "print()\n",
    "print(\"word_to_id['car']:\", word_to_id['car'])\n",
    "print(\"word_to_id['happy']:\", word_to_id['happy'])\n",
    "print(\"word_to_id['lexus']:\", word_to_id['lexus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ptb.train.txt ... \n",
      "Done\n",
      "동시발생 수 계산 ...\n",
      "PPMI 계산 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yang Saewon\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: RuntimeWarning: overflow encountered in long_scalars\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\Yang Saewon\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: RuntimeWarning: invalid value encountered in log2\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0% 완료\n",
      "2.0% 완료\n",
      "3.0% 완료\n",
      "4.0% 완료\n",
      "5.0% 완료\n",
      "6.0% 완료\n",
      "7.0% 완료\n",
      "8.0% 완료\n",
      "9.0% 완료\n",
      "10.0% 완료\n",
      "11.0% 완료\n",
      "12.0% 완료\n",
      "13.0% 완료\n",
      "14.0% 완료\n",
      "15.0% 완료\n",
      "16.0% 완료\n",
      "17.0% 완료\n",
      "18.0% 완료\n",
      "19.0% 완료\n",
      "20.0% 완료\n",
      "21.0% 완료\n",
      "22.0% 완료\n",
      "23.0% 완료\n",
      "24.0% 완료\n",
      "25.0% 완료\n",
      "26.0% 완료\n",
      "27.0% 완료\n",
      "28.0% 완료\n",
      "29.0% 완료\n",
      "30.0% 완료\n",
      "31.0% 완료\n",
      "32.0% 완료\n",
      "33.0% 완료\n",
      "34.0% 완료\n",
      "35.0% 완료\n",
      "36.0% 완료\n",
      "37.0% 완료\n",
      "38.0% 완료\n",
      "39.0% 완료\n",
      "40.0% 완료\n",
      "41.0% 완료\n",
      "42.0% 완료\n",
      "43.0% 완료\n",
      "44.0% 완료\n",
      "45.0% 완료\n",
      "46.0% 완료\n",
      "47.0% 완료\n",
      "48.0% 완료\n",
      "49.0% 완료\n",
      "50.0% 완료\n",
      "51.0% 완료\n",
      "52.0% 완료\n",
      "53.0% 완료\n",
      "54.0% 완료\n",
      "55.0% 완료\n",
      "56.0% 완료\n",
      "57.0% 완료\n",
      "58.0% 완료\n",
      "59.0% 완료\n",
      "60.0% 완료\n",
      "61.0% 완료\n",
      "62.0% 완료\n",
      "63.0% 완료\n",
      "64.0% 완료\n",
      "65.0% 완료\n",
      "66.0% 완료\n",
      "67.0% 완료\n",
      "68.0% 완료\n",
      "69.0% 완료\n",
      "70.0% 완료\n",
      "71.0% 완료\n",
      "72.0% 완료\n",
      "73.0% 완료\n",
      "74.0% 완료\n",
      "75.0% 완료\n",
      "76.0% 완료\n",
      "77.0% 완료\n",
      "78.0% 완료\n",
      "79.0% 완료\n",
      "80.0% 완료\n",
      "81.0% 완료\n",
      "82.0% 완료\n",
      "83.0% 완료\n",
      "84.0% 완료\n",
      "85.0% 완료\n",
      "86.0% 완료\n",
      "87.0% 완료\n",
      "88.0% 완료\n",
      "89.0% 완료\n",
      "90.0% 완료\n",
      "91.0% 완료\n",
      "92.0% 완료\n",
      "93.0% 완료\n",
      "94.0% 완료\n",
      "95.0% 완료\n",
      "96.0% 완료\n",
      "97.0% 완료\n",
      "98.0% 완료\n",
      "99.0% 완료\n",
      "100.0% 완료\n",
      "calculating SVD ...\n",
      "\n",
      "[query] you\n",
      " i 0.7973293662071228\n",
      " we 0.7471123933792114\n",
      " 'd 0.531187891960144\n",
      " 'll 0.5104931592941284\n",
      " 've 0.4996333718299866\n",
      "\n",
      "[query] year\n",
      " week 0.763360321521759\n",
      " month 0.7182248830795288\n",
      " june 0.6444247961044312\n",
      " april 0.5994858741760254\n",
      " july 0.5929083824157715\n",
      "\n",
      "[query] car\n",
      " auto 0.6794116497039795\n",
      " luxury-car 0.6286855340003967\n",
      " luxury 0.5687599182128906\n",
      " vehicle 0.5619687438011169\n",
      " truck 0.5518782734870911\n",
      "\n",
      "[query] toyota\n",
      " nissan 0.6033707857131958\n",
      " laptop 0.5544333457946777\n",
      " minivans 0.48385417461395264\n",
      " complete 0.465953528881073\n",
      " b-2 0.46473264694213867\n"
     ]
    }
   ],
   "source": [
    "window_size = 2\n",
    "wordvec_size = 100\n",
    "\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "vocab_size = len(word_to_id)\n",
    "print('동시발생 수 계산 ...')\n",
    "C = create_co_matrix(corpus, vocab_size, window_size)\n",
    "print('PPMI 계산 ...')\n",
    "W = ppmi(C, verbose=True)\n",
    "\n",
    "print('calculating SVD ...')\n",
    "try:\n",
    "    # truncated SVD (빠르다!)\n",
    "    from sklearn.utils.extmath import randomized_svd\n",
    "    U, S, V = randomized_svd(W, n_components=wordvec_size, n_iter=5,\n",
    "                             random_state=None)\n",
    "except ImportError:\n",
    "    # SVD (느리다)\n",
    "    U, S, V = np.linalg.svd(W)\n",
    "\n",
    "word_vecs = U[:, :wordvec_size]\n",
    "\n",
    "querys = ['you', 'year', 'car', 'toyota']\n",
    "for query in querys:\n",
    "    most_similar(query, word_to_id, id_to_word, word_vecs, top=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 시소러스 기반 기법에서는 단어들의 관련성을 사람이 수작업으로 진행.\n",
    "+ 통계 기반 기법에서는 corpus로부터 단어의 의미를 자동으로 추출, 그 의미를 벡터로 표현한다.\n",
    "+ 구체적으로는 co-ocurrence matrix, PPMI 행렬로 변환하고 SVD를 이용해 차원을 축소시켜 각 단어의 분산 표현을 만든다.\n",
    "+ 이번 장에서는 말뭉치의 text를 다루기 쉽게 해주는 전처리 함수를 몇 개 구현해봤다. 코사인 유사도, most_similar 등등"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
